{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90ecc03",
   "metadata": {},
   "source": [
    "# Face Mask Detection with MobileNetV2 ğŸ­\n",
    "\n",
    "Bu proje, derin Ã¶ÄŸrenme ve bilgisayar gÃ¶rÃ¼sÃ¼ kullanarak yÃ¼z maskesi tespiti yapan bir sistem geliÅŸtirmeyi amaÃ§lamaktadÄ±r. MobileNetV2 mimarisi kullanarak transfer learning yapÄ±lmÄ±ÅŸ ve Kaggle'dan alÄ±nan veri seti ile eÄŸitilmiÅŸtir.\n",
    "\n",
    "## Proje Ã–zellikleri\n",
    "- **Model**: MobileNetV2 (Transfer Learning)\n",
    "- **Veri Seti**: Kaggle - Face Mask Dataset\n",
    "- **SÄ±nÄ±flar**: with_mask, without_mask\n",
    "- **GÃ¶rÃ¼ntÃ¼ Boyutu**: 224x224\n",
    "- **EÄŸitim/Test OranÄ±**: 80/20\n",
    "\n",
    "## AmaÃ§\n",
    "Bir kiÅŸinin yÃ¼z maskesi takÄ±p takmadÄ±ÄŸÄ±nÄ± otomatik olarak tespit etmek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0333f05",
   "metadata": {},
   "source": [
    "## 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi ve Ä°Ã§e AktarÄ±lmasÄ±\n",
    "\n",
    "Projeye baÅŸlamadan Ã¶nce gerekli tÃ¼m kÃ¼tÃ¼phaneleri yÃ¼kleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e57dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel kÃ¼tÃ¼phaneler\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning kÃ¼tÃ¼phaneleri\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# TensorFlow ve Keras kÃ¼tÃ¼phaneleri\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"TensorFlow versiyonu:\", tf.__version__)\n",
    "print(\"KullanÄ±labilir GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005bc6f",
   "metadata": {},
   "source": [
    "## 2. Veri Setinin Ä°ndirilmesi ve KlasÃ¶r YapÄ±sÄ±nÄ±n Ä°ncelenmesi\n",
    "\n",
    "Veri setimiz Kaggle'dan alÄ±nan Face Mask Dataset'tir. Veri setinin yapÄ±sÄ±nÄ± inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15025064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri seti dizin yapÄ±sÄ±\n",
    "data_dir = 'data'\n",
    "categories = ['with_mask', 'without_mask']\n",
    "\n",
    "# Veri setinin mevcut olup olmadÄ±ÄŸÄ±nÄ± kontrol et\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"âœ… Veri seti klasÃ¶rÃ¼ bulundu!\")\n",
    "    \n",
    "    # Her kategori iÃ§in gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±nÄ± say\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if os.path.exists(category_path):\n",
    "            image_count = len(os.listdir(category_path))\n",
    "            print(f\"ğŸ“ {category}: {image_count} gÃ¶rÃ¼ntÃ¼\")\n",
    "        else:\n",
    "            print(f\"âŒ {category} klasÃ¶rÃ¼ bulunamadÄ±!\")\n",
    "    \n",
    "    # Toplam gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±\n",
    "    total_images = sum([len(os.listdir(os.path.join(data_dir, cat))) \n",
    "                       for cat in categories if os.path.exists(os.path.join(data_dir, cat))])\n",
    "    print(f\"\\nğŸ“Š Toplam gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {total_images}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Veri seti klasÃ¶rÃ¼ bulunamadÄ±!\")\n",
    "    print(\"LÃ¼tfen Kaggle'dan veri setini indirin ve 'data' klasÃ¶rÃ¼ne Ã§Ä±karÄ±n.\")\n",
    "    print(\"Veri seti baÄŸlantÄ±sÄ±: https://www.kaggle.com/datasets/omkargurav/face-mask-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d4bed",
   "metadata": {},
   "source": [
    "## 3. Veri Ã–n Ä°ÅŸleme ve GÃ¶rselleÅŸtirme\n",
    "\n",
    "GÃ¶rÃ¼ntÃ¼leri yÃ¼kleyip Ã¶n iÅŸlemden geÃ§irelim ve Ã¶rnek gÃ¶rselleri gÃ¶rselleÅŸtirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88671ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Veri setini yÃ¼kler ve Ã¶n iÅŸlemden geÃ§irir.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¥ Veri seti yÃ¼kleniyor...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if not os.path.exists(category_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ”„ {category} kategorisi iÅŸleniyor...\")\n",
    "        \n",
    "        for i, img_name in enumerate(os.listdir(category_path)):\n",
    "            if i % 500 == 0:\n",
    "                print(f\"   Ä°ÅŸlenen gÃ¶rÃ¼ntÃ¼: {i}\")\n",
    "                \n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            \n",
    "            try:\n",
    "                # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                    \n",
    "                # BGR'dan RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # BoyutlandÄ±r\n",
    "                image = cv2.resize(image, img_size)\n",
    "                \n",
    "                # Array'e dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "                image = img_to_array(image)\n",
    "                \n",
    "                # Normalize et\n",
    "                image = preprocess_input(image)\n",
    "                \n",
    "                data.append(image)\n",
    "                labels.append(category)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Hata: {img_path} - {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"âœ… Toplam {len(data)} gÃ¶rÃ¼ntÃ¼ yÃ¼klendi.\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Veri setini yÃ¼kle\n",
    "if os.path.exists(data_dir):\n",
    "    data, labels = load_data(data_dir)\n",
    "    print(f\"\\nğŸ“Š Veri seti ÅŸekli: {data.shape}\")\n",
    "    print(f\"ğŸ“Š Etiket sayÄ±sÄ±: {len(labels)}\")\n",
    "    print(f\"ğŸ“Š Etiket daÄŸÄ±lÄ±mÄ±:\")\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"   {label}: {count} gÃ¶rÃ¼ntÃ¼\")\n",
    "else:\n",
    "    print(\"âŒ Veri seti yÃ¼klenemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek gÃ¶rÃ¼ntÃ¼leri gÃ¶rselleÅŸtir\n",
    "def visualize_samples(data, labels, num_samples=8):\n",
    "    \"\"\"\n",
    "    Veri setinden Ã¶rnek gÃ¶rÃ¼ntÃ¼leri gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        \n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ normalize et (gÃ¶rselleÅŸtirme iÃ§in)\n",
    "        img = data[i].copy()\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Etiket: {labels[i]}\", fontsize=12)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Veri seti daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtir\n",
    "def plot_class_distribution(labels):\n",
    "    \"\"\"\n",
    "    SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#FF9999', '#66B2FF']\n",
    "    \n",
    "    # Bar grafiÄŸi\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(unique, counts, color=colors)\n",
    "    plt.title('SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('SÄ±nÄ±flar')\n",
    "    plt.ylabel('GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±')\n",
    "    \n",
    "    # DeÄŸerleri bar Ã¼zerine yazdÄ±r\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "                str(count), ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Pasta grafiÄŸi\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(counts, labels=unique, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title('SÄ±nÄ±f OranlarÄ±', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# GÃ¶rselleÅŸtirmeleri Ã§alÄ±ÅŸtÄ±r\n",
    "if 'data' in locals() and 'labels' in locals():\n",
    "    print(\"ğŸ¨ Ã–rnek gÃ¶rÃ¼ntÃ¼ler:\")\n",
    "    visualize_samples(data, labels)\n",
    "    \n",
    "    print(\"\\nğŸ“Š SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
    "    plot_class_distribution(labels)\n",
    "else:\n",
    "    print(\"âŒ Veri seti henÃ¼z yÃ¼klenmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b95618",
   "metadata": {},
   "source": [
    "## 4. Veri Setinin EÄŸitim ve Test Olarak BÃ¶lÃ¼nmesi\n",
    "\n",
    "Veri setimizi %80 eÄŸitim ve %20 test olarak bÃ¶leceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiketleri binary formata Ã§evir\n",
    "label_map = {'without_mask': 0, 'with_mask': 1}\n",
    "\n",
    "if 'labels' in locals():\n",
    "    # Etiketleri sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "    y = np.array([label_map[label] for label in labels])\n",
    "    \n",
    "    print(\"ğŸ”„ Veri seti bÃ¶lÃ¼nÃ¼yor...\")\n",
    "    \n",
    "    # Train-test split (80-20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Veri seti baÅŸarÄ±yla bÃ¶lÃ¼ndÃ¼!\")\n",
    "    print(f\"ğŸ“Š EÄŸitim seti: {X_train.shape[0]} gÃ¶rÃ¼ntÃ¼\")\n",
    "    print(f\"ğŸ“Š Test seti: {X_test.shape[0]} gÃ¶rÃ¼ntÃ¼\")\n",
    "    \n",
    "    # EÄŸitim ve test setlerindeki sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± kontrol et\n",
    "    print(f\"\\nğŸ“Š EÄŸitim seti sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
    "    unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "    for label_num, count in zip(unique_train, counts_train):\n",
    "        label_name = 'with_mask' if label_num == 1 else 'without_mask'\n",
    "        print(f\"   {label_name}: {count} gÃ¶rÃ¼ntÃ¼\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Test seti sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
    "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "    for label_num, count in zip(unique_test, counts_test):\n",
    "        label_name = 'with_mask' if label_num == 1 else 'without_mask'\n",
    "        print(f\"   {label_name}: {count} gÃ¶rÃ¼ntÃ¼\")\n",
    "        \n",
    "    # Veri setinin ÅŸekillerini gÃ¶rselleÅŸtir\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # EÄŸitim seti daÄŸÄ±lÄ±mÄ±\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_labels = ['without_mask', 'with_mask']\n",
    "    plt.bar(train_labels, counts_train, color=['#FF9999', '#66B2FF'])\n",
    "    plt.title('EÄŸitim Seti DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±')\n",
    "    for i, count in enumerate(counts_train):\n",
    "        plt.text(i, count + 10, str(count), ha='center', fontsize=12)\n",
    "    \n",
    "    # Test seti daÄŸÄ±lÄ±mÄ±\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_labels = ['without_mask', 'with_mask']\n",
    "    plt.bar(test_labels, counts_test, color=['#FF9999', '#66B2FF'])\n",
    "    plt.title('Test Seti DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±')\n",
    "    for i, count in enumerate(counts_test):\n",
    "        plt.text(i, count + 2, str(count), ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Veri seti henÃ¼z yÃ¼klenmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac486900",
   "metadata": {},
   "source": [
    "## 5. Veri ArtÄ±rma (Data Augmentation)\n",
    "\n",
    "EÄŸitim performansÄ±nÄ± artÄ±rmak iÃ§in veri artÄ±rma tekniklerini uygulayalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri artÄ±rma parametrelerini tanÄ±mla\n",
    "print(\"ğŸ”„ Veri artÄ±rma (Data Augmentation) ayarlarÄ±:\")\n",
    "\n",
    "# EÄŸitim iÃ§in veri artÄ±rma\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,          # 20 derece dÃ¶ndÃ¼rme\n",
    "    zoom_range=0.15,            # %15 zoom\n",
    "    width_shift_range=0.2,      # GeniÅŸlik kaymasÄ±\n",
    "    height_shift_range=0.2,     # YÃ¼kseklik kaymasÄ±\n",
    "    shear_range=0.15,           # Kesme dÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
    "    horizontal_flip=True,       # Yatay Ã§evirme\n",
    "    fill_mode=\"nearest\",        # Doldurma modu\n",
    "    rescale=1./255             # Normalizasyon\n",
    ")\n",
    "\n",
    "# Test iÃ§in sadece normalizasyon\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"âœ… Veri artÄ±rma ayarlarÄ± hazÄ±rlandÄ±!\")\n",
    "\n",
    "# Veri artÄ±rma Ã¶rneklerini gÃ¶rselleÅŸtir\n",
    "def visualize_augmentation(X, y, datagen, num_samples=8):\n",
    "    \"\"\"\n",
    "    Veri artÄ±rma Ã¶rneklerini gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Bir Ã¶rnek seÃ§\n",
    "    sample_idx = np.random.randint(0, len(X))\n",
    "    sample_image = X[sample_idx:sample_idx+1]\n",
    "    sample_label = y[sample_idx]\n",
    "    \n",
    "    # Orijinal gÃ¶rÃ¼ntÃ¼\n",
    "    plt.subplot(2, 4, 1)\n",
    "    img = sample_image[0].copy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Orijinal\\\\nEtiket: {'Mask' if sample_label == 1 else 'No Mask'}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # ArtÄ±rÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ler\n",
    "    i = 0\n",
    "    for batch in datagen.flow(sample_image, batch_size=1):\n",
    "        i += 1\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        \n",
    "        plt.subplot(2, 4, i+1)\n",
    "        img = batch[0]\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"ArtÄ±rÄ±lmÄ±ÅŸ {i}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Veri artÄ±rma Ã¶rneklerini gÃ¶ster\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\\\nğŸ¨ Veri artÄ±rma Ã¶rnekleri:\")\n",
    "    visualize_augmentation(X_train, y_train, train_datagen)\n",
    "else:\n",
    "    print(\"âŒ EÄŸitim verisi henÃ¼z hazÄ±rlanmadÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808876d9",
   "metadata": {},
   "source": [
    "## 6. Modelin OluÅŸturulmasÄ± (MobileNetV2 ile Transfer Learning)\n",
    "\n",
    "MobileNetV2 mimarisini kullanarak transfer learning ile modelimizi oluÅŸturalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbeb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224, 3), learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    MobileNetV2 tabanlÄ± face mask detection modeli oluÅŸturur.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Model oluÅŸturuluyor...\")\n",
    "    \n",
    "    # MobileNetV2 base model (ImageNet aÄŸÄ±rlÄ±klarÄ± ile)\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=Input(shape=input_shape)\n",
    "    )\n",
    "    \n",
    "    # Base model katmanlarÄ±nÄ± dondur\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Ã–zel katmanlar ekle\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Final modeli oluÅŸtur\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Modeli compile et\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Model baÅŸarÄ±yla oluÅŸturuldu!\")\n",
    "    return model\n",
    "\n",
    "# Model parametreleri\n",
    "IMG_SIZE = (224, 224, 3)\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Modeli oluÅŸtur\n",
    "model = create_model(input_shape=IMG_SIZE, learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Model Ã¶zetini gÃ¶ster\n",
    "print(\"\\\\nğŸ“Š Model Ã–zeti:\")\n",
    "model.summary()\n",
    "\n",
    "# Model mimarisini gÃ¶rselleÅŸtir\n",
    "def plot_model_architecture():\n",
    "    \"\"\"\n",
    "    Model mimarisini gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    print(\"\\\\nğŸ—ï¸ Model Mimarisi:\")\n",
    "    print(\"MobileNetV2 (include_top=False, weights='imagenet', frozen)\")\n",
    "    print(\"         â†“\")\n",
    "    print(\"GlobalAveragePooling2D\")\n",
    "    print(\"         â†“\")\n",
    "    print(\"Dense(128, activation='relu')\")\n",
    "    print(\"         â†“\")\n",
    "    print(\"Dropout(0.3)\")\n",
    "    print(\"         â†“\")\n",
    "    print(\"Dense(1, activation='sigmoid')\")\n",
    "    \n",
    "    # Model parametrelerini gÃ¶ster\n",
    "    total_params = model.count_params()\n",
    "    print(f\"\\\\nğŸ“Š Toplam parametre sayÄ±sÄ±: {total_params:,}\")\n",
    "\n",
    "plot_model_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81a94",
   "metadata": {},
   "source": [
    "## 7. Modelin EÄŸitilmesi\n",
    "\n",
    "Modelimizi eÄŸitim verisiyle eÄŸitelim ve eÄŸitim sÃ¼recini takip edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim parametreleri\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Callbacks tanÄ±mla\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        min_lr=0.000001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "print(f\"ğŸ“Š EÄŸitim parametreleri:\")\n",
    "print(f\"   â€¢ Epoch sayÄ±sÄ±: {EPOCHS}\")\n",
    "print(f\"   â€¢ Batch boyutu: {BATCH_SIZE}\")\n",
    "print(f\"   â€¢ Ã–ÄŸrenme oranÄ±: {LEARNING_RATE}\")\n",
    "\n",
    "# EÄŸitim verisini hazÄ±rla\n",
    "if 'X_train' in locals():\n",
    "    # EÄŸitim verilerini normalize et (veri artÄ±rma iÃ§in)\n",
    "    X_train_norm = X_train.astype('float32') / 255.0\n",
    "    X_test_norm = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Modeli eÄŸit\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_train_norm, y_train, batch_size=BATCH_SIZE),\n",
    "        steps_per_epoch=len(X_train_norm) // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_datagen.flow(X_test_norm, y_test, batch_size=BATCH_SIZE),\n",
    "        validation_steps=len(X_test_norm) // BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Model eÄŸitimi tamamlandÄ±!\")\n",
    "    \n",
    "    # Modeli kaydet\n",
    "    model.save('face_mask_detector.h5')\n",
    "    print(\"ğŸ’¾ Model kaydedildi: face_mask_detector.h5\")\n",
    "    \n",
    "    # EÄŸitim geÃ§miÅŸini kaydet\n",
    "    with open('training_history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    print(\"ğŸ’¾ EÄŸitim geÃ§miÅŸi kaydedildi: training_history.pkl\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ EÄŸitim verisi hazÄ±rlanmadÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556120c8",
   "metadata": {},
   "source": [
    "## 8. Modelin DeÄŸerlendirilmesi\n",
    "\n",
    "EÄŸitilmiÅŸ modelimizi test verisiyle deÄŸerlendirelim ve performans metriklerini inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e87988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # DoÄŸruluk grafiÄŸi\n",
    "    axes[0].plot(history['accuracy'], label='EÄŸitim DoÄŸruluÄŸu', color='blue')\n",
    "    axes[0].plot(history['val_accuracy'], label='DoÄŸrulama DoÄŸruluÄŸu', color='red')\n",
    "    axes[0].set_title('Model DoÄŸruluÄŸu', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('DoÄŸruluk')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # KayÄ±p grafiÄŸi\n",
    "    axes[1].plot(history['loss'], label='EÄŸitim KaybÄ±', color='blue')\n",
    "    axes[1].plot(history['val_loss'], label='DoÄŸrulama KaybÄ±', color='red')\n",
    "    axes[1].set_title('Model KaybÄ±', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('KayÄ±p')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model performansÄ±nÄ± deÄŸerlendir\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Model performansÄ±nÄ± deÄŸerlendirir.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” Model deÄŸerlendiriliyor...\")\n",
    "    \n",
    "    # Test verisi Ã¼zerinde tahmin yap\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Metrikleri hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"âœ… Model deÄŸerlendirme sonuÃ§larÄ±:\")\n",
    "    print(f\"   â€¢ DoÄŸruluk (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   â€¢ Kesinlik (Precision): {precision:.4f}\")\n",
    "    print(f\"   â€¢ DuyarlÄ±lÄ±k (Recall): {recall:.4f}\")\n",
    "    print(f\"   â€¢ F1 Skoru: {f1:.4f}\")\n",
    "    \n",
    "    return y_pred, predictions\n",
    "\n",
    "# Confusion Matrix'i gÃ¶rselleÅŸtir\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=['No Mask', 'Mask']):\n",
    "    \"\"\"\n",
    "    Confusion matrix'i gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('GerÃ§ek Etiket', fontsize=12)\n",
    "    plt.xlabel('Tahmin Edilen Etiket', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "# DeÄŸerlendirmeleri Ã§alÄ±ÅŸtÄ±r\n",
    "if 'history' in locals() and 'X_test' in locals():\n",
    "    # EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir\n",
    "    print(\"ğŸ“Š EÄŸitim geÃ§miÅŸi:\")\n",
    "    plot_training_history(history.history)\n",
    "    \n",
    "    # Model performansÄ±nÄ± deÄŸerlendir\n",
    "    y_pred, predictions = evaluate_model(model, X_test_norm, y_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\\\nğŸ” Confusion Matrix:\")\n",
    "    cm = plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # DetaylÄ± sÄ±nÄ±flandÄ±rma raporu\n",
    "    print(\"\\\\nğŸ“‹ DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Mask', 'Mask']))\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Model henÃ¼z eÄŸitilmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a29f6",
   "metadata": {},
   "source": [
    "## 9. Model ile Tahmin ve SonuÃ§larÄ±n GÃ¶rselleÅŸtirilmesi\n",
    "\n",
    "EÄŸitilmiÅŸ modelimizi kullanarak test gÃ¶rselleri Ã¼zerinde tahmin yapalÄ±m ve sonuÃ§larÄ± gÃ¶rselleÅŸtirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27042cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test gÃ¶rÃ¼ntÃ¼leri Ã¼zerinde tahmin gÃ¶rsellestir\n",
    "def plot_predictions(model, X_test, y_test, num_samples=10):\n",
    "    \"\"\"\n",
    "    Test gÃ¶rÃ¼ntÃ¼leri Ã¼zerinde tahminleri gÃ¶rselleÅŸtirir.\n",
    "    \"\"\"\n",
    "    # Rastgele Ã¶rnekler seÃ§\n",
    "    indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "    \n",
    "    # Tahmin yap\n",
    "    predictions = model.predict(X_test[indices], verbose=0)\n",
    "    \n",
    "    # GÃ¶rselleÅŸtir\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        \n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ normalize et\n",
    "        img = X_test[idx].copy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        # Tahmin ve gerÃ§ek etiketleri al\n",
    "        pred_prob = predictions[i][0]\n",
    "        pred_label = \"Mask\" if pred_prob > 0.5 else \"No Mask\"\n",
    "        true_label = \"Mask\" if y_test[idx] == 1 else \"No Mask\"\n",
    "        \n",
    "        # DoÄŸruluk kontrolÃ¼\n",
    "        correct = (pred_prob > 0.5) == (y_test[idx] == 1)\n",
    "        color = 'green' if correct else 'red'\n",
    "        \n",
    "        # GÃ¶rselleÅŸtir\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'GerÃ§ek: {true_label}\\\\nTahmin: {pred_label}\\\\nOlasÄ±lÄ±k: {pred_prob:.2f}', \n",
    "                 color=color, fontsize=10, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tahmin fonksiyonu\n",
    "def predict_single_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Tek bir gÃ¶rÃ¼ntÃ¼ Ã¼zerinde tahmin yapar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {image_path}\")\n",
    "        \n",
    "        # Ã–n iÅŸlemden geÃ§ir\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Tahmin yap\n",
    "        prediction = model.predict(img, verbose=0)[0][0]\n",
    "        \n",
    "        # Sonucu dÃ¶ndÃ¼r\n",
    "        if prediction > 0.5:\n",
    "            return \"Mask\", prediction\n",
    "        else:\n",
    "            return \"No Mask\", 1 - prediction\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# GÃ¶rselleÅŸtirmeleri Ã§alÄ±ÅŸtÄ±r\n",
    "if 'model' in locals() and 'X_test' in locals():\n",
    "    print(\"ğŸ¯ Test gÃ¶rÃ¼ntÃ¼leri Ã¼zerinde tahmin Ã¶rnekleri:\")\n",
    "    plot_predictions(model, X_test_norm, y_test, num_samples=10)\n",
    "    \n",
    "    # Model Ã¶zeti\n",
    "    print(\"\\\\nğŸ“Š Son Model Ã–zeti:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ğŸ—ï¸ Mimari: MobileNetV2 + Transfer Learning\")\n",
    "    print(f\"ğŸ“ Girdi boyutu: {IMG_SIZE}\")\n",
    "    print(f\"ğŸ¯ SÄ±nÄ±f sayÄ±sÄ±: 2 (Mask, No Mask)\")\n",
    "    print(f\"âš™ï¸ Optimizer: Adam\")\n",
    "    print(f\"ğŸ“‰ Loss: Binary Crossentropy\")\n",
    "    print(f\"ğŸ“ EÄŸitim epoch: {EPOCHS}\")\n",
    "    print(f\"ğŸ“¦ Batch boyutu: {BATCH_SIZE}\")\n",
    "    \n",
    "    if 'history' in locals():\n",
    "        final_accuracy = history.history['val_accuracy'][-1]\n",
    "        final_loss = history.history['val_loss'][-1]\n",
    "        print(f\"âœ… Final doÄŸruluk: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "        print(f\"ğŸ“‰ Final kayÄ±p: {final_loss:.4f}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"âœ… Proje baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "    print(\"ğŸ’¾ Model 'face_mask_detector.h5' olarak kaydedildi.\")\n",
    "    print(\"ğŸš€ ArtÄ±k modeli gerÃ§ek zamanlÄ± tespit iÃ§in kullanabilirsiniz!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Model henÃ¼z eÄŸitilmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0053c3b",
   "metadata": {},
   "source": [
    "## ğŸ‰ SonuÃ§ ve Ä°leriye DÃ¶nÃ¼k AdÄ±mlar\n",
    "\n",
    "Bu projede MobileNetV2 mimarisi kullanarak baÅŸarÄ±lÄ± bir yÃ¼z maskesi tespit sistemi geliÅŸtirdik. \n",
    "\n",
    "### ğŸ“ˆ BaÅŸarÄ±lan Hedefler:\n",
    "- âœ… Kaggle veri setinden yÃ¼z maskesi verilerini iÅŸledik\n",
    "- âœ… MobileNetV2 ile transfer learning uyguladÄ±k\n",
    "- âœ… Veri artÄ±rma teknikleri ile model performansÄ±nÄ± artÄ±rdÄ±k\n",
    "- âœ… Comprehensive model evaluation ve gÃ¶rselleÅŸtirme yaptÄ±k\n",
    "- âœ… GerÃ§ek zamanlÄ± tespit iÃ§in model kaydettik\n",
    "\n",
    "### ğŸš€ Sonraki AdÄ±mlar:\n",
    "1. **GerÃ§ek ZamanlÄ± Tespit**: Webcam ile canlÄ± tespit yapÄ±n\n",
    "2. **Model Ä°yileÅŸtirme**: Fine-tuning ve hyperparameter optimization\n",
    "3. **Deployment**: Web uygulamasÄ± veya mobile app geliÅŸtirin\n",
    "4. **GeniÅŸletme**: FarklÄ± maske tÃ¼rlerini tespit edin\n",
    "\n",
    "### ğŸ“ KullanÄ±m:\n",
    "```python\n",
    "# GerÃ§ek zamanlÄ± tespit iÃ§in:\n",
    "python src/detect.py\n",
    "\n",
    "# Tek gÃ¶rÃ¼ntÃ¼ Ã¼zerinde tahmin iÃ§in:\n",
    "python src/evaluate.py path/to/image.jpg\n",
    "\n",
    "# Model eÄŸitimi iÃ§in:\n",
    "python src/train.py\n",
    "```\n",
    "\n",
    "### ğŸ”— Proje DosyalarÄ±:\n",
    "- `face_mask_detector.h5`: EÄŸitilmiÅŸ model\n",
    "- `training_history.pkl`: EÄŸitim geÃ§miÅŸi\n",
    "- `src/`: Kaynak kod dosyalarÄ±\n",
    "- `data/`: Veri seti klasÃ¶rÃ¼\n",
    "\n",
    "**TeÅŸekkÃ¼rler!** ğŸ­"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
