{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90ecc03",
   "metadata": {},
   "source": [
    "# Face Mask Detection with MobileNetV2 🎭\n",
    "\n",
    "Bu proje, derin öğrenme ve bilgisayar görüsü kullanarak yüz maskesi tespiti yapan bir sistem geliştirmeyi amaçlamaktadır. MobileNetV2 mimarisi kullanarak transfer learning yapılmış ve Kaggle'dan alınan veri seti ile eğitilmiştir.\n",
    "\n",
    "## Proje Özellikleri\n",
    "- **Model**: MobileNetV2 (Transfer Learning)\n",
    "- **Veri Seti**: Kaggle - Face Mask Dataset\n",
    "- **Sınıflar**: with_mask, without_mask\n",
    "- **Görüntü Boyutu**: 224x224\n",
    "- **Eğitim/Test Oranı**: 80/20\n",
    "\n",
    "## Amaç\n",
    "Bir kişinin yüz maskesi takıp takmadığını otomatik olarak tespit etmek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0333f05",
   "metadata": {},
   "source": [
    "## 1. Gerekli Kütüphanelerin Yüklenmesi ve İçe Aktarılması\n",
    "\n",
    "Projeye başlamadan önce gerekli tüm kütüphaneleri yükleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e57dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel kütüphaneler\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning kütüphaneleri\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# TensorFlow ve Keras kütüphaneleri\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"TensorFlow versiyonu:\", tf.__version__)\n",
    "print(\"Kullanılabilir GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Görselleştirme ayarları\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005bc6f",
   "metadata": {},
   "source": [
    "## 2. Veri Setinin İndirilmesi ve Klasör Yapısının İncelenmesi\n",
    "\n",
    "Veri setimiz Kaggle'dan alınan Face Mask Dataset'tir. Veri setinin yapısını inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15025064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri seti dizin yapısı\n",
    "data_dir = 'data'\n",
    "categories = ['with_mask', 'without_mask']\n",
    "\n",
    "# Veri setinin mevcut olup olmadığını kontrol et\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"✅ Veri seti klasörü bulundu!\")\n",
    "    \n",
    "    # Her kategori için görüntü sayısını say\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if os.path.exists(category_path):\n",
    "            image_count = len(os.listdir(category_path))\n",
    "            print(f\"📁 {category}: {image_count} görüntü\")\n",
    "        else:\n",
    "            print(f\"❌ {category} klasörü bulunamadı!\")\n",
    "    \n",
    "    # Toplam görüntü sayısı\n",
    "    total_images = sum([len(os.listdir(os.path.join(data_dir, cat))) \n",
    "                       for cat in categories if os.path.exists(os.path.join(data_dir, cat))])\n",
    "    print(f\"\\n📊 Toplam görüntü sayısı: {total_images}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Veri seti klasörü bulunamadı!\")\n",
    "    print(\"Lütfen Kaggle'dan veri setini indirin ve 'data' klasörüne çıkarın.\")\n",
    "    print(\"Veri seti bağlantısı: https://www.kaggle.com/datasets/omkargurav/face-mask-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d4bed",
   "metadata": {},
   "source": [
    "## 3. Veri Ön İşleme ve Görselleştirme\n",
    "\n",
    "Görüntüleri yükleyip ön işlemden geçirelim ve örnek görselleri görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88671ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Veri setini yükler ve ön işlemden geçirir.\n",
    "    \"\"\"\n",
    "    print(\"📥 Veri seti yükleniyor...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if not os.path.exists(category_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"🔄 {category} kategorisi işleniyor...\")\n",
    "        \n",
    "        for i, img_name in enumerate(os.listdir(category_path)):\n",
    "            if i % 500 == 0:\n",
    "                print(f\"   İşlenen görüntü: {i}\")\n",
    "                \n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            \n",
    "            try:\n",
    "                # Görüntüyü yükle\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                    \n",
    "                # BGR'dan RGB'ye dönüştür\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Boyutlandır\n",
    "                image = cv2.resize(image, img_size)\n",
    "                \n",
    "                # Array'e dönüştür\n",
    "                image = img_to_array(image)\n",
    "                \n",
    "                # Normalize et\n",
    "                image = preprocess_input(image)\n",
    "                \n",
    "                data.append(image)\n",
    "                labels.append(category)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Hata: {img_path} - {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"✅ Toplam {len(data)} görüntü yüklendi.\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Veri setini yükle\n",
    "if os.path.exists(data_dir):\n",
    "    data, labels = load_data(data_dir)\n",
    "    print(f\"\\n📊 Veri seti şekli: {data.shape}\")\n",
    "    print(f\"📊 Etiket sayısı: {len(labels)}\")\n",
    "    print(f\"📊 Etiket dağılımı:\")\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"   {label}: {count} görüntü\")\n",
    "else:\n",
    "    print(\"❌ Veri seti yüklenemedi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek görüntüleri görselleştir\n",
    "def visualize_samples(data, labels, num_samples=8):\n",
    "    \"\"\"\n",
    "    Veri setinden örnek görüntüleri görselleştirir.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        \n",
    "        # Görüntüyü normalize et (görselleştirme için)\n",
    "        img = data[i].copy()\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Etiket: {labels[i]}\", fontsize=12)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Veri seti dağılımını görselleştir\n",
    "def plot_class_distribution(labels):\n",
    "    \"\"\"\n",
    "    Sınıf dağılımını görselleştirir.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#FF9999', '#66B2FF']\n",
    "    \n",
    "    # Bar grafiği\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(unique, counts, color=colors)\n",
    "    plt.title('Sınıf Dağılımı', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Sınıflar')\n",
    "    plt.ylabel('Görüntü Sayısı')\n",
    "    \n",
    "    # Değerleri bar üzerine yazdır\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "                str(count), ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Pasta grafiği\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(counts, labels=unique, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title('Sınıf Oranları', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Görselleştirmeleri çalıştır\n",
    "if 'data' in locals() and 'labels' in locals():\n",
    "    print(\"🎨 Örnek görüntüler:\")\n",
    "    visualize_samples(data, labels)\n",
    "    \n",
    "    print(\"\\n📊 Sınıf dağılımı:\")\n",
    "    plot_class_distribution(labels)\n",
    "else:\n",
    "    print(\"❌ Veri seti henüz yüklenmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b95618",
   "metadata": {},
   "source": [
    "## 4. Veri Setinin Eğitim ve Test Olarak Bölünmesi\n",
    "\n",
    "Veri setimizi %80 eğitim ve %20 test olarak böleceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiketleri binary formata çevir\n",
    "label_map = {'without_mask': 0, 'with_mask': 1}\n",
    "\n",
    "if 'labels' in locals():\n",
    "    # Etiketleri sayısal değerlere dönüştür\n",
    "    y = np.array([label_map[label] for label in labels])\n",
    "    \n",
    "    print(\"🔄 Veri seti bölünüyor...\")\n",
    "    \n",
    "    # Train-test split (80-20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Veri seti başarıyla bölündü!\")\n",
    "    print(f\"📊 Eğitim seti: {X_train.shape[0]} görüntü\")\n",
    "    print(f\"📊 Test seti: {X_test.shape[0]} görüntü\")\n",
    "    \n",
    "    # Eğitim ve test setlerindeki sınıf dağılımını kontrol et\n",
    "    print(f\"\\n📊 Eğitim seti sınıf dağılımı:\")\n",
    "    unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "    for label_num, count in zip(unique_train, counts_train):\n",
    "        label_name = 'with_mask' if label_num == 1 else 'without_mask'\n",
    "        print(f\"   {label_name}: {count} görüntü\")\n",
    "    \n",
    "    print(f\"\\n📊 Test seti sınıf dağılımı:\")\n",
    "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "    for label_num, count in zip(unique_test, counts_test):\n",
    "        label_name = 'with_mask' if label_num == 1 else 'without_mask'\n",
    "        print(f\"   {label_name}: {count} görüntü\")\n",
    "        \n",
    "    # Veri setinin şekillerini görselleştir\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Eğitim seti dağılımı\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_labels = ['without_mask', 'with_mask']\n",
    "    plt.bar(train_labels, counts_train, color=['#FF9999', '#66B2FF'])\n",
    "    plt.title('Eğitim Seti Dağılımı', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Görüntü Sayısı')\n",
    "    for i, count in enumerate(counts_train):\n",
    "        plt.text(i, count + 10, str(count), ha='center', fontsize=12)\n",
    "    \n",
    "    # Test seti dağılımı\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_labels = ['without_mask', 'with_mask']\n",
    "    plt.bar(test_labels, counts_test, color=['#FF9999', '#66B2FF'])\n",
    "    plt.title('Test Seti Dağılımı', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Görüntü Sayısı')\n",
    "    for i, count in enumerate(counts_test):\n",
    "        plt.text(i, count + 2, str(count), ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Veri seti henüz yüklenmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac486900",
   "metadata": {},
   "source": [
    "## 5. Veri Artırma (Data Augmentation)\n",
    "\n",
    "Eğitim performansını artırmak için veri artırma tekniklerini uygulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri artırma parametrelerini tanımla\n",
    "print(\"🔄 Veri artırma (Data Augmentation) ayarları:\")\n",
    "\n",
    "# Eğitim için veri artırma\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,          # 20 derece döndürme\n",
    "    zoom_range=0.15,            # %15 zoom\n",
    "    width_shift_range=0.2,      # Genişlik kayması\n",
    "    height_shift_range=0.2,     # Yükseklik kayması\n",
    "    shear_range=0.15,           # Kesme dönüşümü\n",
    "    horizontal_flip=True,       # Yatay çevirme\n",
    "    fill_mode=\"nearest\",        # Doldurma modu\n",
    "    rescale=1./255             # Normalizasyon\n",
    ")\n",
    "\n",
    "# Test için sadece normalizasyon\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"✅ Veri artırma ayarları hazırlandı!\")\n",
    "\n",
    "# Veri artırma örneklerini görselleştir\n",
    "def visualize_augmentation(X, y, datagen, num_samples=8):\n",
    "    \"\"\"\n",
    "    Veri artırma örneklerini görselleştirir.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Bir örnek seç\n",
    "    sample_idx = np.random.randint(0, len(X))\n",
    "    sample_image = X[sample_idx:sample_idx+1]\n",
    "    sample_label = y[sample_idx]\n",
    "    \n",
    "    # Orijinal görüntü\n",
    "    plt.subplot(2, 4, 1)\n",
    "    img = sample_image[0].copy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Orijinal\\\\nEtiket: {'Mask' if sample_label == 1 else 'No Mask'}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Artırılmış görüntüler\n",
    "    i = 0\n",
    "    for batch in datagen.flow(sample_image, batch_size=1):\n",
    "        i += 1\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        \n",
    "        plt.subplot(2, 4, i+1)\n",
    "        img = batch[0]\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Artırılmış {i}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Veri artırma örneklerini göster\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\\\n🎨 Veri artırma örnekleri:\")\n",
    "    visualize_augmentation(X_train, y_train, train_datagen)\n",
    "else:\n",
    "    print(\"❌ Eğitim verisi henüz hazırlanmadı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808876d9",
   "metadata": {},
   "source": [
    "## 6. Modelin Oluşturulması (MobileNetV2 ile Transfer Learning)\n",
    "\n",
    "MobileNetV2 mimarisini kullanarak transfer learning ile modelimizi oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbeb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224, 3), learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    MobileNetV2 tabanlı face mask detection modeli oluşturur.\n",
    "    \"\"\"\n",
    "    print(\"🔄 Model oluşturuluyor...\")\n",
    "    \n",
    "    # MobileNetV2 base model (ImageNet ağırlıkları ile)\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=Input(shape=input_shape)\n",
    "    )\n",
    "    \n",
    "    # Base model katmanlarını dondur\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Özel katmanlar ekle\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Final modeli oluştur\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Modeli compile et\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Model başarıyla oluşturuldu!\")\n",
    "    return model\n",
    "\n",
    "# Model parametreleri\n",
    "IMG_SIZE = (224, 224, 3)\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Modeli oluştur\n",
    "model = create_model(input_shape=IMG_SIZE, learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Model özetini göster\n",
    "print(\"\\\\n📊 Model Özeti:\")\n",
    "model.summary()\n",
    "\n",
    "# Model mimarisini görselleştir\n",
    "def plot_model_architecture():\n",
    "    \"\"\"\n",
    "    Model mimarisini görselleştirir.\n",
    "    \"\"\"\n",
    "    print(\"\\\\n🏗️ Model Mimarisi:\")\n",
    "    print(\"MobileNetV2 (include_top=False, weights='imagenet', frozen)\")\n",
    "    print(\"         ↓\")\n",
    "    print(\"GlobalAveragePooling2D\")\n",
    "    print(\"         ↓\")\n",
    "    print(\"Dense(128, activation='relu')\")\n",
    "    print(\"         ↓\")\n",
    "    print(\"Dropout(0.3)\")\n",
    "    print(\"         ↓\")\n",
    "    print(\"Dense(1, activation='sigmoid')\")\n",
    "    \n",
    "    # Model parametrelerini göster\n",
    "    total_params = model.count_params()\n",
    "    print(f\"\\\\n📊 Toplam parametre sayısı: {total_params:,}\")\n",
    "\n",
    "plot_model_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81a94",
   "metadata": {},
   "source": [
    "## 7. Modelin Eğitilmesi\n",
    "\n",
    "Modelimizi eğitim verisiyle eğitelim ve eğitim sürecini takip edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim parametreleri\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Callbacks tanımla\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        min_lr=0.000001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"🚀 Model eğitimi başlıyor...\")\n",
    "print(f\"📊 Eğitim parametreleri:\")\n",
    "print(f\"   • Epoch sayısı: {EPOCHS}\")\n",
    "print(f\"   • Batch boyutu: {BATCH_SIZE}\")\n",
    "print(f\"   • Öğrenme oranı: {LEARNING_RATE}\")\n",
    "\n",
    "# Eğitim verisini hazırla\n",
    "if 'X_train' in locals():\n",
    "    # Eğitim verilerini normalize et (veri artırma için)\n",
    "    X_train_norm = X_train.astype('float32') / 255.0\n",
    "    X_test_norm = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Modeli eğit\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_train_norm, y_train, batch_size=BATCH_SIZE),\n",
    "        steps_per_epoch=len(X_train_norm) // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_datagen.flow(X_test_norm, y_test, batch_size=BATCH_SIZE),\n",
    "        validation_steps=len(X_test_norm) // BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Model eğitimi tamamlandı!\")\n",
    "    \n",
    "    # Modeli kaydet\n",
    "    model.save('face_mask_detector.h5')\n",
    "    print(\"💾 Model kaydedildi: face_mask_detector.h5\")\n",
    "    \n",
    "    # Eğitim geçmişini kaydet\n",
    "    with open('training_history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    print(\"💾 Eğitim geçmişi kaydedildi: training_history.pkl\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Eğitim verisi hazırlanmadı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556120c8",
   "metadata": {},
   "source": [
    "## 8. Modelin Değerlendirilmesi\n",
    "\n",
    "Eğitilmiş modelimizi test verisiyle değerlendirelim ve performans metriklerini inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e87988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim geçmişini görselleştir\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Eğitim geçmişini görselleştirir.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Doğruluk grafiği\n",
    "    axes[0].plot(history['accuracy'], label='Eğitim Doğruluğu', color='blue')\n",
    "    axes[0].plot(history['val_accuracy'], label='Doğrulama Doğruluğu', color='red')\n",
    "    axes[0].set_title('Model Doğruluğu', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Doğruluk')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Kayıp grafiği\n",
    "    axes[1].plot(history['loss'], label='Eğitim Kaybı', color='blue')\n",
    "    axes[1].plot(history['val_loss'], label='Doğrulama Kaybı', color='red')\n",
    "    axes[1].set_title('Model Kaybı', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Kayıp')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model performansını değerlendir\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Model performansını değerlendirir.\n",
    "    \"\"\"\n",
    "    print(\"🔍 Model değerlendiriliyor...\")\n",
    "    \n",
    "    # Test verisi üzerinde tahmin yap\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Metrikleri hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"✅ Model değerlendirme sonuçları:\")\n",
    "    print(f\"   • Doğruluk (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   • Kesinlik (Precision): {precision:.4f}\")\n",
    "    print(f\"   • Duyarlılık (Recall): {recall:.4f}\")\n",
    "    print(f\"   • F1 Skoru: {f1:.4f}\")\n",
    "    \n",
    "    return y_pred, predictions\n",
    "\n",
    "# Confusion Matrix'i görselleştir\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=['No Mask', 'Mask']):\n",
    "    \"\"\"\n",
    "    Confusion matrix'i görselleştirir.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Gerçek Etiket', fontsize=12)\n",
    "    plt.xlabel('Tahmin Edilen Etiket', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "# Değerlendirmeleri çalıştır\n",
    "if 'history' in locals() and 'X_test' in locals():\n",
    "    # Eğitim geçmişini görselleştir\n",
    "    print(\"📊 Eğitim geçmişi:\")\n",
    "    plot_training_history(history.history)\n",
    "    \n",
    "    # Model performansını değerlendir\n",
    "    y_pred, predictions = evaluate_model(model, X_test_norm, y_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\\\n🔍 Confusion Matrix:\")\n",
    "    cm = plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Detaylı sınıflandırma raporu\n",
    "    print(\"\\\\n📋 Detaylı Sınıflandırma Raporu:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Mask', 'Mask']))\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Model henüz eğitilmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a29f6",
   "metadata": {},
   "source": [
    "## 9. Model ile Tahmin ve Sonuçların Görselleştirilmesi\n",
    "\n",
    "Eğitilmiş modelimizi kullanarak test görselleri üzerinde tahmin yapalım ve sonuçları görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27042cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test görüntüleri üzerinde tahmin görsellestir\n",
    "def plot_predictions(model, X_test, y_test, num_samples=10):\n",
    "    \"\"\"\n",
    "    Test görüntüleri üzerinde tahminleri görselleştirir.\n",
    "    \"\"\"\n",
    "    # Rastgele örnekler seç\n",
    "    indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "    \n",
    "    # Tahmin yap\n",
    "    predictions = model.predict(X_test[indices], verbose=0)\n",
    "    \n",
    "    # Görselleştir\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        \n",
    "        # Görüntüyü normalize et\n",
    "        img = X_test[idx].copy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        # Tahmin ve gerçek etiketleri al\n",
    "        pred_prob = predictions[i][0]\n",
    "        pred_label = \"Mask\" if pred_prob > 0.5 else \"No Mask\"\n",
    "        true_label = \"Mask\" if y_test[idx] == 1 else \"No Mask\"\n",
    "        \n",
    "        # Doğruluk kontrolü\n",
    "        correct = (pred_prob > 0.5) == (y_test[idx] == 1)\n",
    "        color = 'green' if correct else 'red'\n",
    "        \n",
    "        # Görselleştir\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Gerçek: {true_label}\\\\nTahmin: {pred_label}\\\\nOlasılık: {pred_prob:.2f}', \n",
    "                 color=color, fontsize=10, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tahmin fonksiyonu\n",
    "def predict_single_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Tek bir görüntü üzerinde tahmin yapar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Görüntüyü yükle\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Görüntü yüklenemedi: {image_path}\")\n",
    "        \n",
    "        # Ön işlemden geçir\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Tahmin yap\n",
    "        prediction = model.predict(img, verbose=0)[0][0]\n",
    "        \n",
    "        # Sonucu döndür\n",
    "        if prediction > 0.5:\n",
    "            return \"Mask\", prediction\n",
    "        else:\n",
    "            return \"No Mask\", 1 - prediction\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Görselleştirmeleri çalıştır\n",
    "if 'model' in locals() and 'X_test' in locals():\n",
    "    print(\"🎯 Test görüntüleri üzerinde tahmin örnekleri:\")\n",
    "    plot_predictions(model, X_test_norm, y_test, num_samples=10)\n",
    "    \n",
    "    # Model özeti\n",
    "    print(\"\\\\n📊 Son Model Özeti:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"🏗️ Mimari: MobileNetV2 + Transfer Learning\")\n",
    "    print(f\"📏 Girdi boyutu: {IMG_SIZE}\")\n",
    "    print(f\"🎯 Sınıf sayısı: 2 (Mask, No Mask)\")\n",
    "    print(f\"⚙️ Optimizer: Adam\")\n",
    "    print(f\"📉 Loss: Binary Crossentropy\")\n",
    "    print(f\"🎓 Eğitim epoch: {EPOCHS}\")\n",
    "    print(f\"📦 Batch boyutu: {BATCH_SIZE}\")\n",
    "    \n",
    "    if 'history' in locals():\n",
    "        final_accuracy = history.history['val_accuracy'][-1]\n",
    "        final_loss = history.history['val_loss'][-1]\n",
    "        print(f\"✅ Final doğruluk: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "        print(f\"📉 Final kayıp: {final_loss:.4f}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"✅ Proje başarıyla tamamlandı!\")\n",
    "    print(\"💾 Model 'face_mask_detector.h5' olarak kaydedildi.\")\n",
    "    print(\"🚀 Artık modeli gerçek zamanlı tespit için kullanabilirsiniz!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Model henüz eğitilmedi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0053c3b",
   "metadata": {},
   "source": [
    "## 🎉 Sonuç ve İleriye Dönük Adımlar\n",
    "\n",
    "Bu projede MobileNetV2 mimarisi kullanarak başarılı bir yüz maskesi tespit sistemi geliştirdik. \n",
    "\n",
    "### 📈 Başarılan Hedefler:\n",
    "- ✅ Kaggle veri setinden yüz maskesi verilerini işledik\n",
    "- ✅ MobileNetV2 ile transfer learning uyguladık\n",
    "- ✅ Veri artırma teknikleri ile model performansını artırdık\n",
    "- ✅ Comprehensive model evaluation ve görselleştirme yaptık\n",
    "- ✅ Gerçek zamanlı tespit için model kaydettik\n",
    "\n",
    "### 🚀 Sonraki Adımlar:\n",
    "1. **Gerçek Zamanlı Tespit**: Webcam ile canlı tespit yapın\n",
    "2. **Model İyileştirme**: Fine-tuning ve hyperparameter optimization\n",
    "3. **Deployment**: Web uygulaması veya mobile app geliştirin\n",
    "4. **Genişletme**: Farklı maske türlerini tespit edin\n",
    "\n",
    "### 📝 Kullanım:\n",
    "```python\n",
    "# Gerçek zamanlı tespit için:\n",
    "python src/detect.py\n",
    "\n",
    "# Tek görüntü üzerinde tahmin için:\n",
    "python src/evaluate.py path/to/image.jpg\n",
    "\n",
    "# Model eğitimi için:\n",
    "python src/train.py\n",
    "```\n",
    "\n",
    "### 🔗 Proje Dosyaları:\n",
    "- `face_mask_detector.h5`: Eğitilmiş model\n",
    "- `training_history.pkl`: Eğitim geçmişi\n",
    "- `src/`: Kaynak kod dosyaları\n",
    "- `data/`: Veri seti klasörü\n",
    "\n",
    "**Teşekkürler!** 🎭"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
